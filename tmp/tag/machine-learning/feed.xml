<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="https://hy38.github.io/tag/machine-learning/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://hy38.github.io/" rel="alternate" type="text/html" />
  <updated>2020-02-07T10:44:28+09:00</updated>
  <id>https://hy38.github.io/tag/machine-learning/feed.xml</id>

  
  
  

  
    <title type="html">공익의 IT 블로그 | </title>
  

  
    <subtitle>멋이 있는 사람</subtitle>
  

  

  
    
      
    
  

  
  

  
    <entry>
      <title type="html">ML Coursera 5-1 Neural Networks - Learning</title>
      <link href="https://hy38.github.io/MLcoursera-5-1" rel="alternate" type="text/html" title="ML Coursera 5-1 Neural Networks - Learning" />
      <published>2019-07-31T19:00:00+09:00</published>
      <updated>2019-07-31T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-5-1</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-5-1">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;neural-networks-learning&quot;&gt;Neural Networks: Learning&lt;/h1&gt;

&lt;p&gt;test2&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 4-1 Neural Networks - Representation</title>
      <link href="https://hy38.github.io/MLcoursera-4-1" rel="alternate" type="text/html" title="ML Coursera 4-1 Neural Networks - Representation" />
      <published>2019-07-31T19:00:00+09:00</published>
      <updated>2019-07-31T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-4-1</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-4-1">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;neural-networks-representation&quot;&gt;Neural Networks: Representation&lt;/h1&gt;

&lt;p&gt;test&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 6-1 Advice for Applying Machine Learning</title>
      <link href="https://hy38.github.io/MLcoursera-6-1" rel="alternate" type="text/html" title="ML Coursera 6-1 Advice for Applying Machine Learning" />
      <published>2019-07-31T19:00:00+09:00</published>
      <updated>2019-07-31T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-6-1</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-6-1">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;advice-for-applying-machine-learning&quot;&gt;Advice for Applying Machine Learning&lt;/h1&gt;

&lt;p&gt;지금까지 선형회귀와 분류, 신경망에 대해 알아보았습니다. 이제 이것들을 구현하여 나온 결과값들을 &lt;strong&gt;분석&lt;/strong&gt;하여 어떤 문제점들이 있는지, 어떻게 개선해나가야 할지에 대해 살펴보겠습니다.
또한, 모델을 선택하는데에 있어 몇차식(d)을 사용할지와, 정규화 매개변수인 $\lambda$를 어떻게 정할지를 알아보겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;deciding-what-to-try-next&quot;&gt;Deciding what to try next&lt;/h2&gt;

&lt;p&gt;시작은 집값을 예측하는 linear regression으로 시작하겠습니다.
현재 상황은 이렇습니다 : 
cost function J를 minimize하는 theta를 구하여(train) 그 theta들을 가지고 새로운 데이터에 적용시켜보았더니(test) 예측결과가 영 꽝인 상황입니다.
이 때 어떤것들을 시도해봐야할까요? 아래는 우리가 시도해볼 수 있는 작업들입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;더 많은 데이터를 사용한다.&lt;/li&gt;
  &lt;li&gt;feature의 수를 줄인다.&lt;/li&gt;
  &lt;li&gt;feature의 수를 늘린다.&lt;/li&gt;
  &lt;li&gt;polynomial feature을 추가한다.&lt;/li&gt;
  &lt;li&gt;regularization parameter $\lambda$를 줄이거나 키워본다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;machine-learning-diagnostics&quot;&gt;Machine Learning Diagnostics&lt;/h3&gt;

&lt;p&gt;위 작업들 중에서 어떤 경우에 사용해야하며, 어떤 경우에는 효과가 미미한지를 구별해나갈 것입니다.
예를들어, 데이터를 수집하는데에 소요되는 시간이 6개월이지만, 정작 더 많은 데이터가 있어도 모델이 개선되지 않는다면 6개월의 시간낭비를 한 셈일것입니다.
우리는 &lt;strong&gt;진단&lt;/strong&gt;하는 법을 배움으로써 &lt;strong&gt;Time saving&lt;/strong&gt;을 할 수 있게 될것입니다.&lt;/p&gt;

&lt;h2 id=&quot;evaluation-a-hypothesis&quot;&gt;Evaluation a Hypothesis&lt;/h2&gt;

&lt;p&gt;우리가 학습을 통해 cost function을 minimize하는 $\theta$를 구할때, 과연 이 cost function의 작은 &lt;strong&gt;error&lt;/strong&gt;가 좋은것일지 생각해볼 필요가 있습니다.
너무 적은 error을 갖는 parameter는 &lt;strong&gt;오버피팅&lt;/strong&gt;을 의심하게 만듭니다.
이는 곧 parameter가 &lt;strong&gt;generalize&lt;/strong&gt;를 잘 하지 못함을 의미하며, &lt;strong&gt;새로운 데이터&lt;/strong&gt;에 좋지 않은 결과를 보일것입니다.
$h(\theta)x$를 그려보면 overfitting을 눈대중으로 파악할 수 있겠지만, feature의 개수가 많아질수록 $h(\theta)x$를 그리기가 힘들어지고, 불가능해집니다.&lt;/p&gt;

&lt;p&gt;결국 우리의 가설함수 $h(\theta)x$를 &lt;strong&gt;다른 방법으로 Evaluate&lt;/strong&gt;할 필요성이 생기게 되는데요, 우리가 가진 데이터셋을 70:30의 비율로 쪼개 training set(70%)과 test set(30%)을 만듭니다. 물론 데이터가 섞이도록 shuffle을 해줘야합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/train-test-split.png&quot; alt=&quot;train_test_split&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;train-and-test-scheme&quot;&gt;Train and Test Scheme&lt;/h3&gt;

&lt;p&gt;데이터셋의 분할 이후에는 다음과 같은 순서로 가설함수 $h(\theta)x$를 평가합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;training set(70%)의 데이터를 이용하여 parameter $\theta$를 학습시킨다.&lt;/li&gt;
  &lt;li&gt;30%의 남은 데이터를 이용하여 &lt;strong&gt;Test Error&lt;/strong&gt;을 구한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 때 Test Error $J_test(\theta)$ 은 다음과 같이 구합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;linear regression:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/J-test-linear-regression.png&quot; alt=&quot;J_test_linear_regression&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;logistic regression:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/J-test-logistic-regression.png&quot; alt=&quot;J_test_logistic_regression&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이때 logistic regression에서는 더욱 간소화된 test error을 사용합니다. 이것을 &lt;strong&gt;misclassification error&lt;/strong&gt;라고 부르며, 
이는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/J-test-new-error.png&quot; alt=&quot;J_test_new_error&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/J-test-new-full-function.png&quot; alt=&quot;J_test_new_full_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이것들이 hypothesis의 학습정도를 평가하는 &lt;strong&gt;일반적인&lt;/strong&gt; 방법입니다.&lt;/p&gt;

&lt;h2 id=&quot;model-selection-and-training-validation-test-sets&quot;&gt;Model Selection and training Validation Test Sets&lt;/h2&gt;

&lt;p&gt;다음은 모델 선택시 몇차다항식이 가장 효과적인지 비교하고 가장 효과적인 차수의 다항식을 사용하는 방법을 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;이 때 가설함수가 몇차다항식이냐를 d 로 표현합니다. 3차다항식의 가설함수의 경우에 d는 3이 되겠죠?&lt;/p&gt;

&lt;p&gt;우선, 다음과 같이 d=1 ~ d=10의 총 10개의 가설함수를 만듭니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/ten-hypothesis-function.png&quot; alt=&quot;ten_hypothesis_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 각각의 가설함수에 대해 cost function을 minimize하는 $\theta$를 구합니다. 총 10개의 $\theta$가 나옵니다. 
&lt;strong&gt;이 때 주의할 점은 $\theta$를 구하는 과정에서 training set의 데이터를 이용해야합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;training set을 이용하여 구한 10개의 $\theta$를 이제는 $J_test(\theta)$에 넣어줍니다.&lt;/p&gt;

&lt;p&gt;이 error function 중 가장 적은 error을 갖는 d를 채택하면 됩니다.&lt;/p&gt;

&lt;p&gt;그러나, 이렇게 하면 모델이 training data를 memorise하게된다고 합니다. 실제로도 많이 발생한다고 합니다.&lt;/p&gt;

&lt;p&gt;그래서 더 좋은 방법이 있습니다. 바로 Cross Validation set을 이용하는것인데요,
train, cross validation, test set의 비율을 60 : 20 : 20으로 분할하는 방법입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/split-into-three-sets.png&quot; alt=&quot;split_into_three_sets&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기존과 같이 training set을 이용하여 학습을 시키고, 학습된 $\theta$들을 이용하여 각각의 &lt;strong&gt;Cross Validation Error&lt;/strong&gt;를 구한 후
가장 낮은 &lt;strong&gt;Cross Validation Error&lt;/strong&gt;을 갖는 d를 채택하는 방식입니다.&lt;/p&gt;

&lt;p&gt;달라진 것이라면, test set은 전혀 건들지 않고, test error가 아닌 &lt;strong&gt;cross validation error&lt;/strong&gt;을 이용하여 d를 구한다는 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;diagnosis---bias-vs-variance&quot;&gt;Diagnosis - Bias vs Variance&lt;/h2&gt;

&lt;p&gt;다음으로, 집값을 예측했을 때 예측결과가 High Bias(underfitting)을 겪는지 High Variance(Overfitting)을 겪는지를 판별하는 법을 알아보겠습니다.
이 그래프는 d(다항식의 차수)에 따른 error을 나타내주는 그래프인데요, 이를 통해 성능이 잘 나오지 않는 모델이 underfitting을 겪는지, 혹은 overfitting겪는지 구별할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/Jcv-Jtrain-graph.png&quot; alt=&quot;Jcv_Jtrain_graph&quot; /&gt;
image&lt;/p&gt;

&lt;p&gt;먼저, High Bias인 경우에는 $J_train$과 $J_cv$가 비슷한 높은 error을 갖습니다. 이 경우 underfit을 의심할 수 있습니다.
다음으로, High Variance인 경우에는 $J_cv$가 크고 $J_train$이 작은 error을 갖습니다. 이 경우 overfit이 의심되며, 충분히 자명해보입니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이 그래프는 매우 중요한 그래프이며, overfit과 underfit의 차이를 드러냅니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;regularization-and-biasvariance&quot;&gt;Regularization and Bias/Variance&lt;/h2&gt;

&lt;p&gt;이제 $\lambda$를 고르는 방법에 대해 알아봅시다.
정규화 매개변수인 $\lambda$는 너무 높게 설정하면 underfit(high bias)이, 너무 작게 설정하면 overfit(high variance)이 발생합니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;따라서, 적정한 값의 $\lambda$를 설정하는 것은 좋은 결과를 내는데에 중요한 역할을 합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;다음은 좋은 람다값을 찾는 방법입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;다양한 $\lambda$를 설정한다. (보통 10개)&lt;/li&gt;
  &lt;li&gt;각각의 $\lambda$들의 cost function J($\theta$)를 최소화하는 각각의 $\theta$들을 구한다.&lt;/li&gt;
  &lt;li&gt;이 $\lambda$들에 매칭되는 $\theta$들을 $J_cv(\theta)$에 넣는다.&lt;/li&gt;
  &lt;li&gt;최소의 $J_cv(\theta)$를 갖는 $\theta$를 찾아 $J_test(\theta)$에 넣는다.&lt;/li&gt;
  &lt;li&gt;그 $\lambda$가 잘 골라졌는지 확인한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/lambda-selection.png&quot; alt=&quot;lambda_selection&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이 때의 $J_train, J_cv, J_test$는 모두 regularization term이 삭제된 식임을 주의해주세요.&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Regularization Term : + {\lambda \over 2m} \sum_{j=1}^{m}\theta_j^2&lt;/script&gt;

&lt;p&gt;추가로, 다음 그래프는 $\lambda$에 따른 $J_cv$, $J_train$을 나타낸 것입니다. 위에서 본 그래프와 비교하면 좌우로 대칭이 된것을 확인할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/lambda-graph.png&quot; alt=&quot;lambda_graph&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;learning-curves&quot;&gt;Learning Curves&lt;/h2&gt;

&lt;h3 id=&quot;learning-curve란&quot;&gt;Learning Curve란?&lt;/h3&gt;

&lt;p&gt;learning curve란 성능 향상을, 혹은 알고리즘이 적합한지를 체크(algorithmic sanity check)할 때 주로 사용되는 그래프로,
$J_cv(\theta)$와 $J_train(\theta)$를 m에 따라 나타낸 것입니다.&lt;/p&gt;

&lt;p&gt;이 그래프 또한 &lt;strong&gt;high bias와 high variance를 구별하기 위해&lt;/strong&gt;, 또한 &lt;strong&gt;데이터를 추가해야할지 여부&lt;/strong&gt;에 대해 자주 쓰이므로 잘 알아둘 필요가 있어보입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/learning-curve-general.png&quot; alt=&quot;learning_curve_general&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 $J_train$은 m이 작으면 fitting이 쉽지만, m이 커질수록 모든 data를 fitting하지 못하는 경우가 생기고, 이로인해 $J_train$ error가 증가합니다.&lt;/p&gt;

&lt;p&gt;반면, $J_cv$는 m들이 추가될수록 generalize되기 쉬워지며, 그에 따라 $J_cv$ error가 감소합니다.&lt;/p&gt;

&lt;h3 id=&quot;learning-curve---high-bias&quot;&gt;Learning Curve - High Bias&lt;/h3&gt;

&lt;p&gt;우선, High bias problem 즉 언더피팅의 경우를 살펴봅시다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/learning-curve-underfit.png&quot; alt=&quot;learning_curve_underfit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 경우 그래프의 특징은 &lt;strong&gt;높은 error에서의 수렴&lt;/strong&gt;입니다. 따라서 m의 증가가 error 감소에 아주 미미한 영향을 주게되며, &lt;strong&gt;결과적으로 데이터양의 증가가 결과값 개선에 큰 도움을 주지 못합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이는 낮은 degree의 가설함수를 갖는 $J_cv$가 데이터수에 따른 영향을 적게받기 때문입니다.&lt;/p&gt;

&lt;p&gt;다음 그림을 참고하시면 도움이 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/learning-curve-underfit-m.png&quot; alt=&quot;learning_curve_underfit_m&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;learning-curve---high-variance&quot;&gt;Learning Curve - High Variance&lt;/h3&gt;

&lt;p&gt;다음은 High variance problem 즉 오버피팅의 경우입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/learning-curve-overrfit.png&quot; alt=&quot;learning_curve_overfit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오버피팅 러닝커브의 특징은 &lt;strong&gt;일반적인 m에 대해 아주 높은 $J_cv$를 갖는다는 것&lt;/strong&gt;인데요, 이 때 x축(m)을 연장시켜주면 &lt;strong&gt;낮은 error로 이동&lt;/strong&gt;하는것을 보실수 있습니다. 이와같이 m이 커질수록 $J_cv$가 점점 작아지는것을 확인할 수 있는데요, &lt;strong&gt;결과적으로 많은 데이터가 결과값 개선에 도움을 줍니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이는 높은 degree의 가설함수를 갖는 $J_cv$가 데이터를 잘 fitting하기 때문입니다. 오버피팅의 힘일까요?&lt;/p&gt;

&lt;p&gt;역시 다음 그림을 참고해주세요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week6/learning-curve-overfit-m.png&quot; alt=&quot;learning_curve_overfit_m&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 그래프는 $J_cv$와 $J_train$간의 &lt;strong&gt;Gap&lt;/strong&gt;이 또다른 특징입니다. 이를 통해 쉽게 오버피팅을 파악할 수 있습니다.&lt;/p&gt;

&lt;p&gt;** 이 그래프들은 이상적인 경우의 그래프이며, 실제 데이터를 사용하다보면 훨씬 지저분한 그래프들을 만나게 될 것입니다. **&lt;/p&gt;

&lt;h2 id=&quot;what-to-do-next-revisited&quot;&gt;What to do next (revisited)&lt;/h2&gt;

&lt;p&gt;이번 포스트의 처음에 우리의 결과값이 좋지 않을때 시도해볼 수 있는것들에 대해 나열했었습니다.
이제 그것들을 케이스별로 분류하면서 정리하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;더 많은 데이터를 사용한다.  =&amp;gt; fixes high variance&lt;/li&gt;
  &lt;li&gt;feature의 수를 줄인다.  =&amp;gt; fixes high variance&lt;/li&gt;
  &lt;li&gt;feature의 수를 늘린다.  =&amp;gt; fixes high bias&lt;/li&gt;
  &lt;li&gt;polynomial feature을 추가한다.  =&amp;gt; fixes high bias&lt;/li&gt;
  &lt;li&gt;regularization parameter $\lambda$를 줄인다.  =&amp;gt; fixes high bias&lt;/li&gt;
  &lt;li&gt;regularization parameter $\lambda$를 키운다.  =&amp;gt; fixes high variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;selecting-a-network-architecture&quot;&gt;Selecting a Network Architecture&lt;/h3&gt;

&lt;p&gt;뉴럴넷의 크기를 결정할 때 참고하면 좋을 상황들입니다. 각각 장단점이 존재합니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Small neural network&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;장점 : 연산량이 적다&lt;/li&gt;
  &lt;li&gt;단점 : parameter가 충분하지 않기 때문에 underfitting에 취약하다&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Larger nueral network&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;장점 : 아무래도 좋은 결과값이 나온다.&lt;/li&gt;
  &lt;li&gt;단점 : 연산량이 많아지며, overfitting에 취약하다&lt;/li&gt;
  &lt;li&gt;특이사항 : overfitting은 regularization을 통해 해결할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;종합&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;시작은 하나의 hidden layer로 시작하는 것이 좋다.&lt;/li&gt;
  &lt;li&gt;주로 큰 nueral network를 고른 후 overfitting을 regularization을 통해 해결하는것이 더 좋다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이상으로 6주차의 첫번째 섹션을 알아보았습니다. 결과값이 우리가 원한대로 나오지 않은 경우의 해결법에 대해 알아보았고,
다음 포스트에는 &lt;a href=&quot;/ml/MLcoursera-6-2/&quot;&gt;Machine Learning System Design&lt;/a&gt; 에 대해 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;감사합니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 3-2 Regularization</title>
      <link href="https://hy38.github.io/MLcoursera-3-2" rel="alternate" type="text/html" title="ML Coursera 3-2 Regularization" />
      <published>2019-07-12T19:00:00+09:00</published>
      <updated>2019-07-12T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-3-2</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-3-2">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;regularization&quot;&gt;Regularization&lt;/h1&gt;

&lt;p&gt;이전 포스트를 끝으로 머신러닝의 회귀와 분류에 대해 알아보았습니다. 이제 우리는 &lt;strong&gt;Regularization&lt;/strong&gt; 라고 하는 정규화에 대해 알아보겠습니다.&lt;/p&gt;

&lt;p&gt;Regularization이란, 근본적으로 &lt;strong&gt;Overfitting&lt;/strong&gt;을 해결하기 위한 노력입니다. 그렇다면 오버피팅이란 무엇일까요? 단어를 뜯어보면, 
over(과하게, 많이) + fitting(피팅되다) 정도로 볼 수 있겠네요! 그렇습니다. 우리가 가설함수를 설정할 때 학습데이터를 너무 잘 &lt;strong&gt;끼워맞추기&lt;/strong&gt; 위해
과하게 fitting하는 것이 오버피팅입니다. 여기서 “과하게” 라는것은 가설함수를 너무 복잡하게 설정한다는 것을 의미합니다. 그런데 여기서 학습데이터를
잘 맞추면 좋은것 아닌가요? 라고 할 수 있겠지만, 아쉽게도 오버피팅의 본질적인 문제점은 학습데이터 &lt;strong&gt;“만”&lt;/strong&gt; 잘 맞추고, 시험용데이터나 실전에서는 낮은
정확도를 보인다는 것입니다.반대로 &lt;strong&gt;Underfitting&lt;/strong&gt; 또한 존재합니다. 언더피팅은 너무 간단한 가설함수를 설정하면 발생하는 문제입니다. 
이들을 그림으로 확인하면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/over-under-fitting-image.png&quot; alt=&quot;over_under_fitting_image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 linear regression가설함수가 복잡해짐에 따라 학습용데이터가 잘 fitting되는것을 확인할 수 있습니다. 물론 다음과 같은 Logistic Regression에서도 마찬가지로 발생합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/over-under-fitting-logistic-image.png&quot; alt=&quot;over_under_fitting_logistic_image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;addressing-overfitting&quot;&gt;Addressing Overfitting&lt;/h2&gt;

&lt;p&gt;오버피팅을 다루는 방법은 크게 3가지가 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;첫째, 더 많은 학습데이터를 이용하여 가설함수를 훈련한다.&lt;/li&gt;
  &lt;li&gt;둘째, feature의 수를 줄인다.
    &lt;ul&gt;
      &lt;li&gt;이 경우 수동으로 feature들을 제거하는데, data loss를 최소화하는 지워질 feature들을 고른다. 물론 이럼에도 data loss는 발생한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;셋째, Regularization을 이용한다.
    &lt;ul&gt;
      &lt;li&gt;모든 feature들을 남겨두지만, 매개변수 $\theta$의 크기를 감소시킨다. 이는 각각 조금씩 y결과값 예측에 기여하는 feaeture가 많을 때 유용하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이중에서 우리는 세번째 방법인 Regularization을 이용하여 Overfitting을 해결해볼 것입니다. 
위의 오버피팅된 linear regression 집값예측 그래프를 Regularize하는 것을 설명하겠습니다.
먼저, $\theta$의 크기를 줄이기 위해서 cost function을 다음과 같이 수정합니다. $\theta_3$와 $\theta_4$의 크기를 줄이기(penalize) 위함인데요,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/modified-cost-function.png&quot; alt=&quot;modified_cost_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$\theta_3$와 $\theta_4$의 크기가 많이 줄게 되면 다음 두 항 $\theta_3 x^3$와 $\theta_4 x^4$의 영향력이 거의 사라집니다. 그럼 결국에는 2차다항식만이
남아있는것처럼 보이게됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/linear-regression-regularization.png&quot; alt=&quot;linear_regression_regularization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;cost function에 큰 계수가 붙은 theta를 추가하였을뿐인데, 이것이 어떤 방식으로 theta의 크기를 감소시키는것일까요?&lt;/p&gt;

&lt;p&gt;Cost function은 우리가 최소화해야하는 함수입니다. 그 함수에 엄청나게 큰 계수를 달고있는 $\theta$들을 포함시키게 되면, 기존과 같은 값의 theta들로는
cost function J를 키우기만 할 뿐, 줄이는데 성공하지 못할것입니다. 따라서 J를 minimize하는 $\theta$들 중 큰 계수를 달고 들어온 penalize당하는 
새로운 항들($\theta$)은 자연스럽게 크기가 작아질 수 밖에 없게됩니다. J를 최소화해야하기 때문입니다.&lt;/p&gt;

&lt;p&gt;이로인해 우리는 더욱 간단한 2차다항식의 형태의 hypothesis function을 얻게됩니다.&lt;/p&gt;

&lt;p&gt;정리하면 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;penalize위해 Cost function에 항들을 추가함.&lt;/li&gt;
  &lt;li&gt;Cost function을 minimize하는 과정에서 $\theta_3$와 $\theta_4$의 크기가 줄어들게됨.&lt;/li&gt;
  &lt;li&gt;그러다보니 간단한 hypothesis가 완성되는것처럼 됨.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이번에는, 특정 $\theta$를 penalize하는것이 아닌, $\theta_0$을 제외한 다른 모든 $\theta$들을 penalize하는 방법입니다. 이는 어떤 항들을 penalize해야할지를 고르지 못하는 상황에서 사용합니다.
따라서 이 경우의 항들이 추가된 Cost function은 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta) = {1 \over 2m} * [\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2 + \lambda\sum_{i=1}^n\theta_i^2]&lt;/script&gt;

&lt;p&gt;관습적으로 $\theta_0$는 penalize하지 않는다고 합니다. 사실 $\theta_0$를 penalize하더라도 유의미한 차이가 없다고 하네요. 위와같은 식을 사용하게 되면 이전보다 부드러운 곡선이 등장하게됩니다. data fitting도 잘되고 hypothesis function도 훨씬 좋아집니다.&lt;/p&gt;

&lt;p&gt;위 식에서 새로 보는 문자가 하나 등장합니다. 바로 $\lambda$인데요, 이를 &lt;strong&gt;regularization parameter&lt;/strong&gt;라고 합니다. 우리는 이 $\lambda$를 조절하며 얼마나 regularize할지를 정하는데요, 이 람다가 0이라면, 기존의 일반적인 cost function이 만들어지며, 이는 overfitting이 유지가됩니다. 만일, 람다가 200같이 너무 큰 수로 지정되면, 반대로 세타들을 너무 penalize하게되어 underfitting이 발생하게 됩니다. 이보다 더 큰 수를 람다로 지정하게 되면, penalize하지 않는 $\theta_0$를 제외한 모든 $\theta$들이 거의 없는듯한 효과를 보이게 되므로 $h_\theta(x) = \theta_0$인 상수함수만 남은것처럼 보이게 됩니다.
따라서 regularization parameter $\lambda$를 잘 선택하는것이 중요합니다.&lt;/p&gt;

&lt;h2 id=&quot;regularized-linear-regression&quot;&gt;Regularized Linear Regression&lt;/h2&gt;

&lt;p&gt;위에서 regularization을 이용한 linear regression의 cost function $J(\theta)$에 대해 살펴보았습니다. 이전과 마찬가지로 $J(\theta)$를 minimize하는 $\theta$를 찾아야합니다. 이때, gradient descent를 사용하는데, 우선 이전의 기존 linear regression의 gradient descent식은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/regularized-linear-gradient.png&quot; alt=&quot;regularized_linear_gradient&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 $\theta_0$를 구별해준 것을 알 수 있습니다. $\theta_0$를 penalize하지 않기 때문에 구별한것입니다.&lt;/p&gt;

&lt;p&gt;위 식의 $\theta_j$ 식에 다음과 같이 ${\lambda \over m}\theta_j$을 추가해줍니다. 참고로 이 식은 cost function $J(\theta)$의 편미분 결과입니다.&lt;/p&gt;

&lt;p&gt;이 떄, 위 $\theta_j$의 update 식을 $\theta_j(1 - \alpha{\lambda \over m})$로 묶어낼 수 있습니다. 
여기서 다음 항을 주목할 필요가 있습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(1 - \alpha{\lambda \over m})&lt;/script&gt;

&lt;p&gt;주로 alpha는 작은수, m은 큰 수이기 때문에, 위 항은 1보다 작게됩니다. 주로 0.95 ~ 0.99 사이의 값들을 갖게 되는데, 이 수치들을 $\theta_j$에 매 update시마다 곱해주게 됩니다. 그 이외의 항은 기존 gradient descent와 동일합니다.&lt;/p&gt;

&lt;p&gt;이를 통해 보다 직관적으로 $\theta_j$를 매 update마다 감소시킴을 알 수 있습니다. $\theta$값들의 penalize가 이렇게 작동합니다.&lt;/p&gt;

&lt;h3 id=&quot;regularization-with-the-normal-equation&quot;&gt;Regularization with the Normal Equation&lt;/h3&gt;

&lt;p&gt;$J(\theta)$를 minimize하기위한 방법중 하나인 normal equation을 이용한 방법으로도 regularization을 진행할 수 있습니다. 기존의 linear regression의 normal equation식은 다음과 같았습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta = (X^TX)^{-1}X^Ty&lt;/script&gt;

&lt;p&gt;기억이 안나시면 &lt;a href=&quot;/ml/MLcoursera-2-1/&quot;&gt;여기&lt;/a&gt;를 참고해주세요!&lt;/p&gt;

&lt;p&gt;위 기존 normal equation에서 다음과 같이 항을 추가하여 regularization을 진행하게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/normal-equation-regularization.png&quot; alt=&quot;normal_equation_regularization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 추가된 항인 $\lambda[matrix]$에서 행렬의 첫번째 원소가 0인 이유는 j=0일 때 $\theta_j$를 penalize하지 않기 위함입니다.&lt;/p&gt;

&lt;p&gt;Normal Equation을 이용할 때 항상 고려하게 되는것이 바로 &lt;strong&gt;Non-invertibility&lt;/strong&gt;인데요, 딱히 고려할 필요가 없어집니다.
그 이유는, $(X^TX + \lambda[matrix])$가 항상 invertible하기 때문입니다.&lt;/p&gt;

&lt;p&gt;따라서, 기존의 $X^TX$항이 $m \le n$ 이면 invertible하다는 조건을 따질 필요가 없어졌습니다. 여러모로 regularization을 이용하면 좋아지네요!&lt;/p&gt;

&lt;h2 id=&quot;regularization-for-logistic-regression&quot;&gt;Regularization for Logistic Regression&lt;/h2&gt;

&lt;p&gt;마지막으로 Logistic Regression에서의 Regularization에 대해 살펴보겠습니다.
Logistic Regression을 regularize하는 과정이 Linear Regression과 비슷합니다.&lt;/p&gt;

&lt;p&gt;먼저 cost function $J(\theta)$에 다음 항을 추가합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;+{\lambda \over 2m}\sum_{j=1}^n\theta_j^2&lt;/script&gt;

&lt;p&gt;완성된 $J(\theta)$는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/regularized-logistic-cost-function.PNG&quot; alt=&quot;regularized_logistic_cost_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;추가된 항의 sum이 j=1부터 시작됨을 유의해주세요. 이는 j=0일 때의 $\theta_0$를 penalize하지 않겠다는 뜻입니다.&lt;/p&gt;

&lt;p&gt;이제 cost function J에 gradient descent를 적용해보겠습니다.&lt;/p&gt;

&lt;p&gt;기존의 logistic regression의 $\theta$ update rule은 다음과 같았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/original-logistic-gradient-descent.png&quot; alt=&quot;original_logistic_gradient_descent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 linear regression과 동일한 방법으로 다음과 같은 식을 유도할 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/modified-logistic-gradient-descent.png&quot; alt=&quot;modified_logistic_gradient_descent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 $\theta$ update rule이 regularized linear regression과 동일하게됨을 알 수 있습니다. 
&lt;strong&gt;다만, 가설함수가 다르기 때문에, 식만 같을뿐이지, 실제로 동일하지는 않습니다.&lt;/strong&gt;&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 3-1 Logistic Regression</title>
      <link href="https://hy38.github.io/MLcoursera-3-1" rel="alternate" type="text/html" title="ML Coursera 3-1 Logistic Regression" />
      <published>2019-06-08T19:00:00+09:00</published>
      <updated>2019-06-08T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-3-1</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-3-1">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;/ml/MLcoursera-1-1/&quot;&gt;Introduction&lt;/a&gt;에서 언급했듯이 &lt;strong&gt;지도학습&lt;/strong&gt;은 크게 회귀(Regression)와 분류(Classification)로 나눌 수 있습니다.
이전까지 우리는 회귀에 대해 간단히 알아보았습니다. 다음으로 분류에 대해 알아볼 차례입니다.&lt;/p&gt;

&lt;h1 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h1&gt;

&lt;p&gt;우리는 이제 Classification 알고리즘인 logistic regression에 대해 살펴보겠습니다. 다만 이에앞서, 많은 분들이 왜 Classification을 공부하는데 regression을 배우는지에 대해 궁금하실 수 있다고 생각합니다. 물론 저도 그랬었고요. “logistic &lt;strong&gt;REGRESSION&lt;/strong&gt;“이라고 이름이 붙여진 것은 역사상의 이유라고 합니다. 따라서 이는 기본적으로 분류를 위한 알고리즘이며, 회귀라는 이름이 있다고 해서 회귀라고 생각하면 안될 것 같습니다. 이에 대한 보다 자세한 설명은 아래 링크에 나와있습니다.&lt;/p&gt;

&lt;p&gt;++ &lt;a href=&quot;https://www.quora.com/Why-is-logistic-regression-called-regression-if-it-doesnt-model-continuous-outcomes&quot;&gt;Why is logistic regression called regression&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;분류에서 기본적으로 y는 discrete한 값이어야 합니다. 예를 들어, 어떤 이메일이 스팸인지(1) 아닌지(0), 혹은 어떤 종양이 악성인지(1) 양성인지(0)와 같이 0, 1, 2, 3, … (혹은 1, 2, 3, 4, …등 이산적인 값들을 y에 사용합니다.&lt;/p&gt;

&lt;p&gt;먼저, binary class classification problem을 살펴보겠습니다. 사실 binary와 multiclass classification problem은 거의 비슷합니다. 다만, 마지막에 one vs all classification을 적용하게 되는데, 이는 뒤에서 다시 살피도록 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;linear-regression-to-a-classification-problem&quot;&gt;linear regression to a Classification Problem?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/linear-regression-to-classification-problem.png&quot; alt=&quot;linear_regression_to_classification_problem&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형회귀에 분류를 적용하려면, 일정 값 이상이면 1, 미만이면 0 등의 분류 임계값이 필요한데, 이를 &lt;strong&gt;threshold&lt;/strong&gt;라고 합니다. 위 그림에서는 threshold가 0.5임을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;위 그림처럼 이전에 공부한 선형회귀를 분류에도 적용시킬 수 있다면 너무 편할것 같습니다. 하지만 아쉽게도 몇가지 문제점들이 발생하게 됩니다. 한번 분류문제에 선형회귀를 시도해보면서 그 문제점들을 파악해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;위 그림만 보면 얼핏 잘 fitting되는것처럼 보이기도 합니다. 하지만 위 데이터셋에 매우 작은 종양 크기의 Malignant한 종양이 발견된다면 자칫 많은 데이터들이 이상하게 분류될 수 있는 상황이 발생합니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;ol&gt;
      &lt;li&gt;우리가 예측하는 y값은 0 혹은 1 등의 값이지만, linear regression을 위한 hypothesis function이 주는 결과값은 0보다 작을 수도, 1보다 클 수도 있습니다. 따라서 우리는 0 혹은 1의 값을 갖도록 만들어줄 필요가 있을 것입니다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hypothesis-representation&quot;&gt;Hypothesis Representation&lt;/h2&gt;

&lt;h3 id=&quot;가설함수의-조건&quot;&gt;가설함수의 조건&lt;/h3&gt;

&lt;p&gt;우리가 분류에 사용할 가설함수 $h_\theta(x)$는 0과 1사이의 값을 가지면 좋을 것 같습니다. 다음과 같이 말입니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 \leq h_\theta(x) \leq 1&lt;/script&gt;

&lt;p&gt;이를 만족하는 함수가 있는데, 바로 &lt;strong&gt;sigmoid function&lt;/strong&gt; 입니다. 이 함수의 식은 ${1 \over  1+e^{-x}}$ 입니다.
&lt;a href=&quot;https://www.desmos.com/calculator/bgontvxotm&quot;&gt;Desmos&lt;/a&gt;를 이용하여 그려보면, 다음과 같은 그래프를 띕니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/desmos-sigmoid-graph.PNG&quot; alt=&quot;desmos_sigmoid_graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우리는 이 식을 이용하여 가설함수를 세울 것입니다. 이 때 기존의 선형회귀 가설함수 식인 &lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta^Tx&lt;/script&gt; 에 g라는 함수를 합성한 함수인 &lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = g(\theta^Tx)&lt;/script&gt; 라는 식을 얻어서 이 식의 $\theta^Tx$를 $z$로 치환하는 과정을 거칩니다. 그 결과 다음과 같은 함수가 나옵니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_\theta(x) = g(z) = {1 \over  1+e^{-z}}&lt;/script&gt;

&lt;h3 id=&quot;가설함수-output값의-해석&quot;&gt;가설함수 output값의 해석&lt;/h3&gt;

&lt;p&gt;우리가 세운 가설함수 h(x)가 숫자를 반환할 때, 우리는 이를 &lt;strong&gt;해당 x가 input으로 들어갔을 때 y=1이 되는 확률&lt;/strong&gt;이라 합니다.
예를들어 주어진 x 값이 어떤 환자의 의료데이터(종양의 크기, 모양 등)라 했을 때, output이 h(x) = 0.83 이라고 나오게 된다면, 이 환자의 종양이 악성일 확률은 83%가 되는 것 입니다.&lt;/p&gt;

&lt;p&gt;이러한 것을 식으로 표현하면 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_\theta(x) = P(y=1 | x; \theta)&lt;/script&gt;

&lt;p&gt;또한, 우리가 다루는 이진분류(Binary Classification)에서 다음이 성립합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(y=1 \vert x; \theta) + P(y=0 \vert x; \theta) = 1&lt;/script&gt;

&lt;p&gt;우리가 갖게 될 y값은 0 아니면 1이기 때문이죠.&lt;/p&gt;

&lt;h2 id=&quot;decision-boundary&quot;&gt;Decision Boundary&lt;/h2&gt;

&lt;p&gt;우리의 가설함수 h(x) = g(z) 는 시그모이드 함수 입니다. h(x)가 0.5 이상일 경우 y=1, 0.5 미만일 경우 y=0 이라고 분류를 하게 되는 것입니다.
이 때, g(z)가 0.5 이상인 부분은 그래프상에서 확인 가능하듯이 &lt;strong&gt;z가 양수&lt;/strong&gt;인 경우입니다. 우리는 z를 $\theta^Tx$로 정의했으므로, 다음과 같을 경우에 h(x)가 0.5보다 커지며, 이는 y=1이라는 output을 만들어냅니다.&lt;/p&gt;

&lt;p&gt;if $ \theta^Tx \ge 0 $  then $h_\theta(x) \ge 0.5,$ $y=1$&lt;/p&gt;

&lt;p&gt;따라서, $ \theta^Tx \ge 0.5 $ 일 때 $y = 1$ 이 성립합니다. 우리는 이를 이용해 Decision Boundary라는 경계를 만들어낼 수 있습니다.&lt;/p&gt;

&lt;p&gt;추가로, g(z)가 0.5인 경우에는 주로 y=1로 판정하기는 하지만, 그 판정이 틀릴확률이 높다는 것을 염두해야 할 것 같습니다.&lt;/p&gt;

&lt;p&gt;본격적으로, 다음과 같은 가설함수에, 데이터셋이 주어졌을 경우의 분류를 생각해봅시다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_\theta(x) = g(z) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_2) = g(\theta^Tx)&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/decision-boundary-data.png&quot; alt=&quot;decision_boundary_data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 단순한 데이터셋을 분류하려면 어떤 방법이 있을까요?
상식적으로는, 둘 사이에 직선을 긋는 방법이 있을 것 같습니다.&lt;/p&gt;

&lt;p&gt;하지만, 컴퓨터는 상식을 모릅니다. 따라서, 직선을 긋게되는 원칙과 방법을 알려주어야 합니다.&lt;/p&gt;

&lt;p&gt;h(x)가 y=1 이라는 결과값을 도출해내는 과정의 중심에는 $\theta^Tx \ge 0$ 이 있었습니다. 따라서, 이 $\theta^Tx \ge 0$, 즉 $z$가 0보다 크거나 같은 경우는 1, 작은 경우는 0을 분류해내도록 만들면 됩니다.&lt;/p&gt;

&lt;p&gt;위 가설함수에서 $z$는 $\theta_0 + \theta_1 x_1 + \theta_2 x_2$ 입니다. 우리는 이 $\theta$값들에 다음과 같은 값을 정해줘보겠습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_0 = -3, \theta_1 = 1, \theta_2 = 1&lt;/script&gt;

&lt;p&gt;위 경우 $z$는 &lt;strong&gt;y=1일 때&lt;/strong&gt; 다음과 같은 부등식이 성립합니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;-3x_0 + 1x_1 + 1x_2 \ge 0&lt;/script&gt;

&lt;p&gt;그리고 위 식을 정리하면, 고등학교 수학시간에 배운 단순한 “부등식의 영역” 문제가 됩니다.
저 영역을 만족하는 x들의 경우 y=1이 되는것이지요. 그림으로 그리면, 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/decision-boundary.png&quot; alt=&quot;decision_boundary&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음과 같이 두 데이터를 가르는 직선을 긋는 방법이 있겠죠.
이 때, 이 직선이 바로 &lt;strong&gt;Decision Boundary&lt;/strong&gt; 입니다.&lt;/p&gt;

&lt;p&gt;신기한 점은, 이 Decision Boundary는 가설함수와 매개변수만을 이용하여 세운것이며, 어떠한 데이터도 사용되지 않았다는 점입니다. 우리는 데이터를 적절한 매개변수를 찾는데 사용하게 되는데, 이렇게 해서 얻어진 매개변수가 위 그림의 경우 $\theta^T = [-3, 1, 1]$ 이라고 보시면 될 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;non-linear-decision-boundaries&quot;&gt;Non-linear Decision Boundaries&lt;/h3&gt;

&lt;p&gt;Decision Boundary는 linear하지 않을수도 있습니다. 다음과 같은 Decision Boundary도 존재합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/decision-boundary-nonlinear.png&quot; alt=&quot;decision_boundary_nonlinear&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 경우에는 가설함수 $h_\theta(x)$가 다음과 같습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_\theta(x) = g(\theta_0 + \theta_1 x_1 + \theta_2 x_1^2 + \theta_4 x_2^2&lt;/script&gt;

&lt;p&gt;이 가설함수에 데이터셋을 이용하여 가장 적절한 매개변수를 찾아보았더니 $\theta^T = [-1, 0, 1, 1]$ 였고, 이를 통해 우리는 $x_1^2 + x_2^2 \ge 1$ 이라는 반지름이 1인 원의 바깥부분에 해당하는 x값들이 y=1을 output으로 준다는 것을 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;추가적으로, 원보다 더욱 고차원의 복잡한 decision boundary를 만드는 것 또한 가능합니다. 이 때는 $z$를 복잡하게 설정해주면 되겠죠?&lt;/p&gt;

&lt;h2 id=&quot;cost-function-for-logistic-regression&quot;&gt;Cost Function for Logistic Regression&lt;/h2&gt;

&lt;p&gt;Cost function의 본질은 결국 가장 적절한 매개변수 $\theta$를 찾아내는 것입니다. 이는 cost가 가장 적은 parameter를 채택하면서 이루어집니다. 앞선 linear regression이 그랬듯이, logistic regression에서도 본질은 변하지 않습니다.&lt;/p&gt;

&lt;p&gt;linear regression에서의 cost function $J(\theta)$는 다음과 같았습니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta) = {1 \over m}\sum_{i=1}^m {1 \over 2} (h_\theta(x^{(i)}) - y^{(i)})^2&lt;/script&gt;

&lt;p&gt;이해의 편의를 위해서 logistic regression에서는, linear regression의 cost인 $ {1 \over 2} (h_\theta(x^{(i)}) - y^{(i)})^2  $을 통째로 $ Cost(h_\theta(x), y) $로 바꾸어봅시다. Cost function의 기능(m개 데이터의 cost들의 합)이 똑같이 유지되도록 말이죠. J를 바꾼 결과 다음과 같은 식이 만들어집니다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta) = {1 \over m}\sum_{i=1}^m Cost(h_\theta(x), y)&lt;/script&gt;

&lt;p&gt;이렇게까지 식을 변형하는 이유는, 기존의 Squared Error Function에 logistic regression의 가설함수 h(x) = g(z) 를 대입하면 문제가 생기기 때문인데요. linear regression의 가설함수 h(x)의 경우 &lt;strong&gt;linearity&lt;/strong&gt;, 즉 선형이기 때문에 결과적으로 &lt;strong&gt;convex&lt;/strong&gt;한 function이었습니다. 하지만, logistic regression의 가설함수 h(x) = g(z)의 경우, 시그모이드 함수 $ h_\theta(x) = g(z) = {1 \over  1+e^{-z}} $가 비선형; 즉 선형결합으로 표현될 수 없기 때문에, &lt;strong&gt;non-convex&lt;/strong&gt;한 function이 됩니다.&lt;/p&gt;

&lt;p&gt;구체적으로 &lt;strong&gt;non-convex&lt;/strong&gt;함을 확인해보면 다음과 같습니다. 먼저, 가설함수 g(z)가 비선형이기 때문에&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cost(h_\theta(x), y) = {1 \over 2} (h_\theta(x) - y)^2 = {1 \over 2}({1 \over  1+e^{-\theta^Tx}} - y)^2&lt;/script&gt;

&lt;p&gt;위 식을 다시 $J(\theta)$에 대입하여 $\theta$와 $J(\theta)$에 대한 그래프를 plot 해보게 되면 다음과 같은 모양이 나옵니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/too-many-local-minimums.png&quot; alt=&quot;too_many_local_minimums&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cost function J가 수많은 local minimum을 갖게되며, 이는 Gradient Descent를 이용하여 &lt;strong&gt;global minimum&lt;/strong&gt;을 찾는것을 어렵게합니다.&lt;/p&gt;

&lt;p&gt;따라서 가설함수가 &lt;strong&gt;convex&lt;/strong&gt;한지 여부는 굉장히 중요합니다. 이에 따라 우리는 $ Cost(h_\theta(x), y) $를 &lt;strong&gt;convex&lt;/strong&gt;한 식으로 변경할 것입니다. 새로운 Cost는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/convex-logistic-regression-cost.png&quot; alt=&quot;convex_logistic_regression_cost&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이것이 우리가 logistic regression에서 사용할 cost이고, 따라서 우리의 cost function $J(\theta)$는 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/convex-logistic-regression-cost-function.png&quot; alt=&quot;convex_logistic_regression_cost_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 추가로 y가 1이든 0이든 관계없이 간소화된(simplified) 하나의 식으로 병합을 할 수 있는데, 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/simplified-cost-function.png&quot; alt=&quot;simplified_cost_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이는 y가 무조건 0 혹은 1이기에 가능한 것 입니다.&lt;/p&gt;

&lt;p&gt;Cost Function J에 대한 소개는 마쳤고, 이 함수에 Gradient Descent를 적용하기 이전에, Cost Function에 대해 어떻게 저 함수가 나왔는지에 대한 이해를 하고 넘어가겠습니다. 이것은 다시 다음 식에서 시작됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/convex-logistic-regression-cost.png&quot; alt=&quot;convex_logistic_regression_cost&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cost라 함은 기본적으로 우리가 세운 가설의 결과값과 실제 결과데이터값의 &lt;strong&gt;차이&lt;/strong&gt;를 의미합니다. 가설함수가 y=0을 예측했는데 y=1이 정답이었다면, 엄청나게 큰 비용, 즉 $ \infty $ Cost 를 초래하겠죠. 반대로, 가설함수가 y=1을 예측했는데, 정답 역시 예측한대로 y=1이라면, 0의 비용을 초래할 것입니다. 이러한 것들을 잘 설명해주는 함수가 $ -log(h_\theta(x)) $입니다. 다음과 같은 y=-log(x)그래프를 띄며, 방금 내용이 쉽게 이해가 갈 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/cost-when-y-equals-one.png&quot; alt=&quot;cost_when_y_equals_one&quot; /&gt;&lt;/p&gt;

&lt;p&gt;y=0일때의 경우를 생각해보세요! 비슷한 방식으로 접근하면 이해하실 수 있으실 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;minimizing-cost-function-with-gradient-descent&quot;&gt;Minimizing Cost Function with Gradient Descent&lt;/h2&gt;

&lt;p&gt;이제껏 구해온 Cost Function J를 이제는 최소화할 차례입니다.&lt;/p&gt;

&lt;p&gt;가장 적은 cost를 갖는 $\theta$를 찾은 후 가설함수에 테스트 데이터 $x$를 넣어서 나오는 결과값이 바로 $h_\theta(x)$이며 이것은 y=1일 확률을 나타내줍니다.&lt;/p&gt;

&lt;p&gt;이전에 linear regression의 Gradient Descent는 다음과 같았습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/multiple-features-gradient-descent-new.png&quot; alt=&quot;cost_when_y_equals_one&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Logistic Regression의 Gradient Descent 또한 위와 같습니다..!
이는 logistic regression의 cost function $J(\theta)$를 편미분해보면 알 수 있는데요, 다음과 같은 과정을 거칩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/partial-derivative-1.png&quot; alt=&quot;partial_derivative_1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/partial-derivative-2.png&quot; alt=&quot;partial_derivative_2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우리는 for-loop을 이용하여 $\theta$를 update할 수 있지만, 더 나은 vectorization을 이용할 수도 있습니다. 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/vectorized-gradient-descent.png&quot; alt=&quot;vectorized_gradient_descent&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;advanced-optimization&quot;&gt;Advanced Optimization&lt;/h2&gt;

&lt;p&gt;Gradient Descent를 구현할 때에는 다음과 같은 과정을 거칩니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;$J(\theta)$와 그 편미분을 구현한다.&lt;/li&gt;
  &lt;li&gt;위 둘을 gradient descent식에 대입한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이런 Gradient descent보다 향상된 알고리즘이 몇 있습니다. 바로 Confugate gradient, BFGS, L-BFGS입니다. 이들의 장점은 learning rate $\alpha$를 자동으로 잡아주고 속도도 기존의 경사하강법보다 빠르다는 것입니다. 그러한 이유로 커다란 머신러닝 문제(huge feature set)들에 자주 쓰입니다.&lt;/p&gt;

&lt;h2 id=&quot;multiclass-classification-problems&quot;&gt;Multiclass Classification Problems&lt;/h2&gt;

&lt;p&gt;지금까지 두 개의 class만이 존재하는 이진분류(Binary Classification)을 해왔다면, 실제로 많이 쓰일 다중분류에 대해 알아보겠습니다.
다중분류는 이진분류의 연장선이며, 맨 윗부분에서 잠깐 언급한 &lt;strong&gt;one vs all classification&lt;/strong&gt;을 이용합니다.&lt;/p&gt;

&lt;h3 id=&quot;one-vs-all-classification&quot;&gt;One vs All Classification&lt;/h3&gt;

&lt;p&gt;방법은 간단합니다. 각 클래스마다 이진분류를 진행합니다. 다음과 같이 말입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week3/one-vs-all-classification.png&quot; alt=&quot;one_vs_all_classification&quot; /&gt;&lt;/p&gt;

&lt;p&gt;새로운 데이터 $x$를 받아 $h_\theta(x)^{(i)}$가 최대가 되는 i 클래스를 찾습니다. 그 i 클래스를 채택합니다.&lt;/p&gt;

&lt;p&gt;구체적으로는, 각각 학습한 세 개의 이진분류 가설함수들에 새로운 데이터 x를 평가해보라한 뒤, y=1일 그 확률이 가장 큰 클래스를 사용하는 것입니다.&lt;/p&gt;

&lt;p&gt;이것으로 Classification에 대한 소개를 마칩니다. 다음 포스트에서는 &lt;a href=&quot;/ml/MLcoursera-3-2/&quot;&gt;Regularization&lt;/a&gt;에 대해 알아보겠습니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 2-1 Linear Regression with Multiple Variables</title>
      <link href="https://hy38.github.io/MLcoursera-2-1" rel="alternate" type="text/html" title="ML Coursera 2-1 Linear Regression with Multiple Variables" />
      <published>2019-05-31T19:00:00+09:00</published>
      <updated>2019-05-31T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-2-1</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-2-1">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;linear-regression-with-multiple-variables&quot;&gt;Linear Regression with Multiple Variables&lt;/h1&gt;

&lt;h2 id=&quot;intro&quot;&gt;Intro&lt;/h2&gt;
&lt;p&gt;안녕하세요. 이번 포스트에서는 multiple variables(features)를 가진 선형회귀에 대해 알아보겠습니다.
지난 포스트에서 하나의 variable을 가지는 선형회귀를 공부했는데, 그 연장선이라고 보시면 됩니다.
우리는 지도학습에서 선형회귀, 분류를 공부한 다음 비지도학습 등 더욱 다양한 것들을 공부할 것입니다. 따라서 이 포스트 다음으로는 기본적인 Octave 설명을 다루고, 곧바로 분류(Classification)을 공부하게 되겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;notation&quot;&gt;Notation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/multiple-features-data.png&quot; alt=&quot;multiple_features_data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;먼저, 위와 같은 데이터를 봐주세요. 이전의 포스트에서는 단순히 집의 크기에 대한 가격을 예상하는 선형회귀를 배웠다면, 이번에는 더욱 구체적으로 들어가서 다양한 features를 기반으로 집가격을 예상하게 됩니다. 그에 앞서서 표기법에 대해 정리하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;x의 밑첨자는 각각의 feature들을 의미합니다. 예를들어 침실의 개수에 관한 데이터는 $x_2$입니다.&lt;/li&gt;
  &lt;li&gt;y는 이전과 같이 output variable, 즉 집가격을 의미합니다.&lt;/li&gt;
  &lt;li&gt;m : 이전에 설명한것과 같이 example의 갯수를 말합니다. 위의 테이블에서는 각각의 row들이 각 집들의 데이터이기 때문에, 총 4개의 집 example이 있어 m은 4입니다.&lt;/li&gt;
  &lt;li&gt;n : features의 갯수들입니다. 위 테이블에서는 크기, 침실갯수, 몇층인지, 몇년되었는지 해서 총 4개의 feature가 있네요.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$x^i$&lt;/strong&gt; : 하나의 example에 대한 vector입니다. 쉽게 말해서 하나의 row를 뜻합니다. $x^3$은 세번째 row인 [1534 3 2 30] 벡터를 가리키게 됩니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$x_j^i$&lt;/strong&gt; : i번째 row data의 j번째 feature의 값 을 가리킵니다. 이를테면 $x_4^3$은 30을 가리키겠죠?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;changed-hypothesis&quot;&gt;Changed Hypothesis&lt;/h2&gt;
&lt;p&gt;기존의 단일변수 선형회귀에서는 다음과 같은 가설함수를 이용했습니다.
&lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta_0 + \theta_1x&lt;/script&gt;
그러나, 더 많은 features들이 생겨남에 따라 이 식을 변경시킬 필요성이 생깁니다.
결과적으로 우리는 다음과 같은 가설함수를 세우게 됩니다.
&lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 + \theta_4x_4&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;여기서 $x_0$을 1로 설정하게 된다면, &lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 + \theta_4x_4&lt;/script&gt; 가 위의 식과 동일해 보이게 될 것입니다. 다만, $x_0$라는 feature가 추가로 생겨나게 되면서, &lt;strong&gt;feature vector&lt;/strong&gt;의 &lt;strong&gt;dimension&lt;/strong&gt;은 n에서 n+1 로 커집니다. &lt;strong&gt;parameter&lt;/strong&gt;인 $\theta$의 &lt;strong&gt;dimension&lt;/strong&gt;은 기존과 같은 n+1이 됩니다. 이로써 두 &lt;strong&gt;column vector&lt;/strong&gt;들의 &lt;strong&gt;dimension&lt;/strong&gt;이 동일해졌습니다.&lt;/p&gt;

&lt;p&gt;다시 이 가설함수를 볼까요?
&lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 + \theta_4x_4&lt;/script&gt;
이것을 선형대수를 이용하여 간단하게 표현하면,
&lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta^TX&lt;/script&gt;
로 표현할 수 있습니다..!! 엄청난 식의 간소화를 진행한 셈이죠!
이 때 $h_\theta(x)$의 &lt;strong&gt;dimension&lt;/strong&gt;은 [1 x n+1] * [n+1 x 1] = [1 x 1]이 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent-for-multiple-variables&quot;&gt;Gradient Descent for Multiple Variables&lt;/h2&gt;
&lt;p&gt;가설함수 설정을 마친 우리는, 이제 경사하강법(Gradient Descent)를 적용해볼 것입니다. 이에 앞서 다음과 같이 개별적인 $\theta$들로 이루어진 우리의 cost function J함수 &lt;script type=&quot;math/tex&quot;&gt;J(\theta_0, \theta_1, ... , \theta_n)&lt;/script&gt; 의 parameter을 dimension이 n+1인 $\theta$ &lt;strong&gt;벡터&lt;/strong&gt;로 바꾸어주도록 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/multiple-features-cost-function.png&quot; alt=&quot;multiple_features_cost_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마찬가지로 우리의 gradient descent algorithm또한 parameter을 변경해주도록 합시다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/multiple-features-gradient-descent.png&quot; alt=&quot;multiple_features_gradient_descent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 이 알고리즘은 다음과 같이 표기될 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/multiple-features-gradient-descent-new.png&quot; alt=&quot;multiple_features_gradient_descent_new&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 식의 끝에 $x^{(j)}_i$가 붙은것은 편미분의 결과로 해석됩니다.&lt;/p&gt;

&lt;p&gt;이로써 gradient descent가 multiple variables에 대하여 어떻게 달라지는지에 대해 간단하게 살펴보았습니다.&lt;/p&gt;

&lt;p&gt;아래의 식은 굉장히 중요한 역할을 함을 기억하면 좋을것 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/gradient-descent-partial-derivative.png&quot; alt=&quot;gradient_descent_partial_derivative&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;feature-scaling&quot;&gt;Feature Scaling&lt;/h2&gt;
&lt;p&gt;하나가 아닌 multiple variable를 갖는 문제에서는 이 variable들이 너무나 큰 &lt;strong&gt;range&lt;/strong&gt; 차이가 나게되면 gradient descent를 진행할 경우 다음과 같이 진행하게 됩니다. 이렇게 진행하게 될 경우에는 궁극적인 global minimum에 도달하기까지 오랜 시간이 걸리게 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/gradient-descent-bad.png&quot; alt=&quot;gradient_descent_bad&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서 우리는 빠른 global minimum으로의 수렴을 위해 variables / features 들이 비슷한 range를 갖도록 다듬어주는 feature scaling이라는 작업을 진행하게 됩니다.&lt;/p&gt;

&lt;p&gt;feature scaling의 결과는 놀랍습니다. 타원이었던 $J(\theta)$ 그래프의 이심율이 점차 작아지면서 원의 형태를 띄게 됩니다.&lt;/p&gt;

&lt;p&gt;가장 좋은 범주는 $ -1 \leq x_(i) \leq 1 $ 혹은 $ -0.5 \leq x_(i) \leq 0.5 $ 라고 합니다.&lt;/p&gt;

&lt;h3 id=&quot;mean-normalization&quot;&gt;Mean Normalization&lt;/h3&gt;
&lt;p&gt;feature scaling의 technique 중 하나인 mean normalization을 이용하여 range들을 일정하게 통일시키는 방법을 보여드리겠습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/mean-normalization.png&quot; alt=&quot;mean_normalization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 식을 이용하여 mean normalization을 진행하게 됩니다. 그렇다면 우리가 &lt;a href=&quot;https://stats.stackexchange.com/questions/157923/feature-scaling-and-mean-normalization&quot;&gt;다음과 같은 문제&lt;/a&gt;에서 normalized된 $x_2^{(4)}$를 구하는 것을 보여드리겠습니다. 위 식의 $x_i$에 $x_2^{(4)}$를 대입하고, $\mu_i$에 &lt;strong&gt;mean&lt;/strong&gt; 즉 평균을 대입하고, $s_i$에는 최댓값에서 최솟값을 뺀 &lt;strong&gt;range&lt;/strong&gt;값을 대입하거나 표준편차를 대입하여 진행합니다.(분명 range 대입시와 표준편차 대입시의 결과는 다릅니다.)&lt;/p&gt;

&lt;p&gt;위 링크의 문제에서 $s_i = 8836 − 4761 = 4075$이고, $x_i = 4761$, $\mu_i = 6675.5$이므로, 정답 $x_2^{(4)}$는 -0.47입니다.
이 때에는 $s_i$를 구하기 위하여 &lt;strong&gt;range&lt;/strong&gt;를 채택하였습니다.&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent-tips&quot;&gt;Gradient Descent Tips&lt;/h2&gt;
&lt;p&gt;다음은 경사하강법을 진행할 때의 팁입니다.
learning rate $\alpha$를 채택하는&lt;/p&gt;

&lt;h3 id=&quot;plot-debugging&quot;&gt;Plot Debugging&lt;/h3&gt;
&lt;p&gt;x축에 iteration의 횟수, y축에 $J(\theta)$를 plot으로 그려보면, 다음 그림과 같이 더이상 감소하지 않는 구간이 생깁니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/plot-debugging.png&quot; alt=&quot;plot_debugging&quot; /&gt;&lt;/p&gt;

&lt;p&gt;물론 y축인 $J(\theta)$가 항상 감소하게끔 너무 큰 $\alpha$를 잡지 않도록 주의해야합니다. $\alpha$가 너무 큰 경우에는 overshooting이 발생할 수 있습니다. 따라서 적당한 $\alpha$를 설정해야합니다. 이때의 팁은 알파를 3배씩 증감시켜주면서 조절하는 것입니다. 예를들어 0.01, 0.03, 0.003 등과 같이 말입니다. 이들 0.01, 0.03, 0.003 등의 alpha에 대한 plot들을 비교해보면서 적절한 alpha를 찾아내는 과정이 중요하겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;automatic-convergence-test&quot;&gt;Automatic Convergence Test&lt;/h3&gt;
&lt;p&gt;iteration이 유의미한 차이를 더이상 만들어내지 못할 때에 iteration을 중지시키고 최소가 되는 $J(\theta)$를 구하는 방법 또한 존재합니다. 다만, 이 방법의 아쉬운 점은 유의미한 차이인 threshold를 찾아내는것이 쉽지 않다는 것입니다. 이 threshold가 적절하지 않으면, 한참 내려가고 있을 때에 iteration을 중지시키게 될 수도 있습니다.
따라서 plot을 활용하여 x값이 일직선이 이루어지는 $J(\theta)$를 찾아내는 방법이 보편적입니다.&lt;/p&gt;

&lt;h2 id=&quot;choice-of-features-and-polynomial-regression&quot;&gt;Choice of Features and Polynomial Regression&lt;/h2&gt;

&lt;h3 id=&quot;choosing-the-most-appropriate-feature&quot;&gt;Choosing the most appropriate Feature&lt;/h3&gt;
&lt;p&gt;우리가 집값을 예측함에 있어서 불필요한 feature를 사용하고 있을지도 모릅니다. 예를들어 집의 넓이를 중요한 feature로 생각하며 집을 구하고있는데, 주어진 feature이 고작 가로($x_1$)와 세로($x_2$) 길이(length)라면, &lt;strong&gt;새로운 feature을 만들어서 사용할 수도 있습니다.&lt;/strong&gt; 새로운 feature는 $x_1 * x_2$(가로 * 세로)이겠죠. 이렇게 하면 2개의 feature을 1개로 줄일 수 있게됩니다. 그리고 이는 다음과 같은 가설함수를 설정할 수 있어보입니다.
&lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta_0 + \theta_1x_3&lt;/script&gt;
이를 통해 알 수 있듯이, 새로운 feature을 만들어서 사용하게되면 좋은 모델을 만들어 낼 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;polynomial-regression&quot;&gt;Polynomial Regression&lt;/h3&gt;
&lt;p&gt;처음에 polynomial regression을 linear regression에서 접하였을 때에 문득 무언가가 이상하다는 생각이 들었습니다. 선형회귀를 하는데, polynomial regression이 갑자기 튀어나와 당황했었습니다. 아래 링크는 linear regression이 parameter에 있어 linear함을 설명해줍니다. 참고해주세요.&lt;/p&gt;

&lt;p&gt;++ &lt;a href=&quot;https://www.quora.com/Why-is-linear-regression-called-linear-if-we-can-use-quadratic-equations-in-our-model-which-gives-a-curved-line&quot;&gt;why polynomial regression is in the category of linear regression&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;우리가 linear regression으로 데이터를 fitting하는데에 한계를 느낄때에는 polynomial regression을 이용할 수 있습니다. 이 때 우리의 가설함수 &lt;script type=&quot;math/tex&quot;&gt;h_\theta(x) = \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3&lt;/script&gt;에서의  $x_1$은 $x$, $x_2$는 $x^2$, $x_3$은 $x^3$로 매핑시켜주면 됩니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/polynomial-regression.png&quot; alt=&quot;polynomial_regression&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 데이터의 경우에는 꼭지점 이후에 내려가는 오목한 2차 다항식보다는 3차 다항식이 더 잘 들어맞는것같죠?
3차다항식 이외에도 제곱근 함수 $\sqrt{x}$($x^{1\over2}$)를 이용하면 더 적절한 데이터 피팅이 될 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;normal-equation&quot;&gt;Normal Equation&lt;/h2&gt;
&lt;p&gt;여태까지 우리는 linear regression문제들을 해결하기 위해 gradient descent를 이용하여 데이터에 가장 잘 들어맞는 가설함수를 찾아나갔습니다.
하지만, gradient descent 외에도 &lt;strong&gt;normal equation&lt;/strong&gt;을 이용하여 데이터를 피팅할 수 있습니다. 살짝 복잡하긴 하지만, 많지 않은 데이터를 다룰때에는 gradient descent보다 빠르게 산술적으로 $\theta$값들을 구하게 됩니다.&lt;/p&gt;

&lt;p&gt;정규방정식을 이용한 해를 구하는 식은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/normal-equation.png&quot; alt=&quot;normal_equation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 식에 대한 자세한 풀이는 좋은 강의영상으로 대체하겠습니다.&lt;/p&gt;

&lt;p&gt;++ &lt;a href=&quot;https://www.edwith.org/linearalgebra4ai/lecture/24131/&quot;&gt;정규방정식을 이용한 해 구하기&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 이제 정규방정식을 이용하여 주어진 데이터에 맞는 $\theta$값을 구해보도록 하겠습니다. 우선, 데이터는 이번 포스트 시작할 때 사용되었던 multiple features가 있는 집값예측 데이터입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/multiple-features-data.png&quot; alt=&quot;multiple_features_data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;정규방정식에서의 X는 design matrix로써, 모든 feature정보를 [m x n+1] matrix에 담습니다. n+1은 $x_0$ feature의 column을 추가한 것 입니다.마찬가지로, 정규방정식에서의 y는 [m x 1] matrix의 column vector로 정의됩니다.&lt;/p&gt;

&lt;p&gt;위의 데이터를 이용하여 정규방정식에 대입하게 되면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/normal-equation-2.png&quot; alt=&quot;normal_equation_2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 식을 계산하면 cost function을 최소화하는, 즉 데이터에 가장 적합한 $\theta$값을 구하게 됩니다.
한번 계산해볼까요?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week2/normal-equation-result.png&quot; alt=&quot;normal_equation_result&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그렇다면, 언제 어떤 경우에 &lt;strong&gt;gradient descent&lt;/strong&gt;를 쓰고, 어떨때 &lt;strong&gt;normal equation&lt;/strong&gt;을 써야할까요?
먼저 &lt;strong&gt;Gradient Descent&lt;/strong&gt;의 장단점을 나열해보겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;장점
    &lt;ul&gt;
      &lt;li&gt;엄청난 양의 데이터를 다룰 때 빠르다.
        &lt;ul&gt;
          &lt;li&gt;엄청난 양이라 함은 n이 10000보다 큰 경우를 뜻한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;단점
    &lt;ul&gt;
      &lt;li&gt;learning rate $\alpha$를 정해야한다.&lt;/li&gt;
      &lt;li&gt;iteration을 사용하기 때문에 속도가 느리다.($O(kn^2)$)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;반면에, &lt;strong&gt;Normal Equation&lt;/strong&gt;의 장단점은 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;장점
    &lt;ul&gt;
      &lt;li&gt;learning rate $\alpha$를 정할 필요가 없으며, convergence를 체크할 필요가 없다.&lt;/li&gt;
      &lt;li&gt;iteration을 사용하지 않기 때문에 속도가 빠른 편이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;단점
    &lt;ul&gt;
      &lt;li&gt;역행렬을 연산할 필요가 있으며, 이는 $O(n^3)$의 시간복잡도를 갖는다.&lt;/li&gt;
      &lt;li&gt;n이 커질수록 연산속도가 느려진다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;따라서, 보통 n이 10000을 넘지 않는 경우에는 간단하게 normal equation을 이용하여 cost function을 최소화하는 $\theta$값을 구하고,
n이 10000보다 큰 엄청난 양의 데이터의 경우에는 gradient descent를 이용하여 적절한 $\theta$값을 구합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;normal-equation-and-non-invertibility&quot;&gt;Normal Equation and non-invertibility&lt;/h3&gt;
&lt;p&gt;선형대수를 공부하셨기 때문에 정규방정식에서 쓰이는 역행렬이 &lt;strong&gt;존재하지 않으면&lt;/strong&gt; 어쩌지라는 생각을 하셨을 수도 있습니다.
다행이도, MATLAB이나 octave의 경우 &lt;strong&gt;pinv&lt;/strong&gt; 라는 pseudo inverse function이 존재하여 non-invertible한 matrix에 대해서도 올바른 값을 계산해줍니다.&lt;/p&gt;

&lt;p&gt;그렇다면 마지막으로 $X^TX$가 non-invertible하다는 것이 갖는 의미에 대해 알아보겠습니다. 일반적으로는 두 가지 원인이 있습니다.&lt;/p&gt;

&lt;p&gt;첫째는 불필요한 feature들이 존재할 경우입니다.
두번째는 너무 많은 feature들이 존재할 경우입니다. 예를들어, feature의 개수 n이 m보다 훨씬 많은 경우에 $X^TX$가 가끔 비가역성인 경우가 생기게됩니다. 너무 많은 feature들은 추후에 배울 &lt;strong&gt;&lt;a href=&quot;https://hy38.github.io/ml/MLcoursera-3-2/&quot;&gt;regularization&lt;/a&gt;&lt;/strong&gt;을 이용하여 문제를 해결하거나, feature들을 지워나가면서 해결할 수 있습니다.&lt;/p&gt;

&lt;p&gt;또한, linearly dependent한 feature을 지우는 방법도 있다고 합니다.&lt;/p&gt;

&lt;p&gt;지금까지 Linear Regression with Multiple Variables 에 대해 알아보았습니다. 다음 시간에는 Octave / Matlab Tutorial을 건너뛰고 &lt;strong&gt;Logistic Regression&lt;/strong&gt;에 대해 포스팅하겠습니다.
오탈자 / 오류 / 궁금사항 댓글로 남겨주시면 적극 반영하여 더욱 발전된 모습을 보여드리겠습니다. 궁금하신 것이 있으시면 언제든지 댓글을 남겨주시기 바랍니다. 감사합니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 1-2 Linear Regression with One Variable</title>
      <link href="https://hy38.github.io/MLcoursera-1-2" rel="alternate" type="text/html" title="ML Coursera 1-2 Linear Regression with One Variable" />
      <published>2019-05-28T19:00:00+09:00</published>
      <updated>2019-05-28T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-1-2</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-1-2">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;linear-regression-with-one-variable&quot;&gt;Linear Regression with One Variable&lt;/h1&gt;

&lt;p&gt;머신러닝에 대한 간단한 소개를 마친 우리는 이제 선형회귀에 대하여 알아볼 것입니다. 우선 몇가지 사전 지식이 필요합니다. 선형회귀를 하기 위해서는 회기를 위한 데이터가 필요한데요, 이것을 &lt;strong&gt;training set&lt;/strong&gt; 이라고 합니다. 이와 더불어 간단한 표기법들을 정리하면 수월할 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;간단한-표기법-정리&quot;&gt;간단한 표기법 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;m : training example의 갯수&lt;/li&gt;
  &lt;li&gt;x’s : input variables / features&lt;/li&gt;
  &lt;li&gt;y : output variable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이전 포스트의 집값예측문제에서 그래프 상에 위치한 X들의 개수가 m이 될 것이고, 그 X의 x축 좌표를 x, y축 좌표를 y라고 지금은 편의상 인지하시면 됩니다.&lt;/p&gt;

&lt;p&gt;선형 회귀에서 우리의 궁극적인 목적은, 주어진 데이터에 가장 정확히 들어맞는 일직선을 찾는 것입니다. 그렇게 된다면 자기가 사고싶은 집크기에 따른 가격을 알아낼 수 있을테니 말입니다.(혹은 그 반대)&lt;/p&gt;

&lt;p&gt;그렇기 때문에 우리는 hypothesis function이라는 가설함수 h(x)를 이용하여 데이터에 가장 근접한 line을 fitting합니다. 일직선이기 때문에 h(x)는 다음과 같은 모습을 띕니다.&lt;br /&gt;
&lt;img src=&quot;/assets/images/ml/coursera/week1/hypothesis.png&quot; alt=&quot;hypothesis_function&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우리가 대학교 이전에 배운 일차함수들은 모두 y = ax + b 라고 배웠지만, 여기서는 사뭇 달라지기 때문에 참고하여 이해하면 좋을것 같습니다.
위의 h(x) 처럼 1개의 variable을 가진 선형회귀를 &lt;strong&gt;univariate linear regression&lt;/strong&gt; 이라고 합니다. 말 그대로 단일변수 선형회귀 입니다. 이 역시 기억해두면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;cost-function-j&quot;&gt;Cost Function J&lt;/h2&gt;

&lt;p&gt;Cost function이라 함은 
우리가 regression을 할 때에 hypothesis function을 세우고 진행합니다. 그리고 hypothesis function의 세타값들을 변화시켜가며 최적의 선을 찾아냅니다. 그렇다면 이 최적의 선은 어떠한 방식으로 찾아내는 것일까요? 이를 찾아내는 함수가 따로 있습니다. 바로 &lt;strong&gt;Cost Function&lt;/strong&gt;입니다. 임의의 세타값들을 대입한 경우 그 선이 데이터와 얼마나 잘 들어맞는가 (혹은 얼마나 어긋나는가)를 평가해준다고 생각하시면 되겠습니다. 우리는 이 Cost Function을 J를 이용하여 표기합니다.&lt;/p&gt;

&lt;p&gt;Cost function은 모든 데이터에 대하여 각 데이터가 가설함수의 선과 얼마나 떨어져있는지를 계산하여 제곱을 합니다. 그리고 이들을 모두 더한 것을 2m 으로 나누어줍니다. (m은 위에서 언급했듯이 training example의 갯수입니다.) squared error cost function이라고도 불리는 이 함수를 수식화하면 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/cost-function.png&quot; alt=&quot;cost_function&quot; /&gt;
2m으로 나누어줌으로써 각 데이터별 차이도의 평균을 구하게 되는 것입니다. 이 때 m이 아닌 2m으로 나누어 주는 이유는 추후에 이 식을 미분할 때의 편의성을 고려한 것입니다.&lt;/p&gt;

&lt;p&gt;위의 내용을 바탕으로 정리하면, Cost function J는 우리가 만든 가설함수와 실제 데이터와의 차이도를 나타내주는 함수이므로, 그 차이도가 적을수록 실제 데이터에 들어맞는 가설함수를 세웠다고 할 수 있을 것입니다. 따라서 우리는 최적의 선을 만들기 위해서는 cost function J를 &lt;strong&gt;최소화&lt;/strong&gt;해야 할 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/cost-function-minimize.png&quot; alt=&quot;cost_function_minimize&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;그렇다면 이쯤에서 드는 의문이 cost function을 어떻게 &lt;strong&gt;최소화할 것인가&lt;/strong&gt; 입니다.
우리는 Gradient Descent라는 경사하강법 알고리즘을 사용할 것인데, 이를 설명하기에 앞서서 cost function을 3D 모델화한 그림을 보겠습니다.
참고로 우리의 데이터는 다음 그림처럼 (1, 1), (2, 2), (3, 3)으로 가장 정확한 가설함수는 h(x) = 0 + 1x 일 것입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/linear-data.png&quot; alt=&quot;linear_data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/convex-3D-plot.png&quot; alt=&quot;convex_3D_plot&quot; /&gt;
위의 도자기(?)모양과 같은 그래프가 나오는데, 이를 통해 알수있는 것은 두가지 입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;이 Cost function J는 최소값 1개를 갖는다. 
-이 때에 J가 &lt;strong&gt;convex&lt;/strong&gt;하다고 합니다.&lt;/li&gt;
  &lt;li&gt;최소의 J를 갖는 h(x)의 두 variables의 값들을 알아낼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(추가적으로 contour plot을 이용하여 직관적인 이해를 할 수도 있지만, 생략하겠습니다.)&lt;/p&gt;

&lt;p&gt;다시 본론으로 돌아와서, 위의 convex한 J에 대하여 최소가 되게하는 두 variable들(세타값들)을 어떻게 찾는지 설명하겠습니다.
우리는 &lt;strong&gt;아무 점에서 시작&lt;/strong&gt;하여 산을 타고 내려가듯이 J가 낮은곳으로 이동을 할 것입니다. 구체적으로는 세타값들을 미세하게 변경해가며 J를 줄여나가는 것입니다. 이 과정을 더이상 내려갈 곳이 없는 &lt;strong&gt;local minimum&lt;/strong&gt;에 수렴(도달)할 때까지 반복합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/gradient-decent-3D.png&quot; alt=&quot;gradient_descent_3D&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다만, 주의할 것은 local minimum이 global minimum이 아닐 수 있다는 것입니다. 위 그림과 같이 여러개의 local minimum이 있는 경우에는 시작점이 조금만 달라져도 끝나는 점이 아예 달라질 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition&quot;&gt;formal definition&lt;/h3&gt;

&lt;p&gt;이제 이 신기한 Gradient descent algorithm이 어떠한 수학적 방식으로 세타값들을 변경해나가는지 알아봅시다.
먼저, 수식을 보겠습니다. 이 수식을 수렴할 때까지 반복합니다.
&lt;strong&gt;이 수식은 매우 중요합니다.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/theta-update-rule.png&quot; alt=&quot;theta_update_rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;기본적인 미적분을 학습했다는 전제하에 진행하겠습니다.&lt;/strong&gt;
위 수식에서 처음 보는 문자 알파(alpha)가 나옵니다. 이는 &lt;strong&gt;learning rate&lt;/strong&gt;을 나타내며, gradient descent를 얼마나 크게 크게 내려갈 것인지(혹은 작게 작게)를 결정하는 역할을 합니다.
대입연산자 := 를 이용하여 새로운 세타값을 업데이트하는 것 입니다. 이 때 &lt;strong&gt;주의할 점&lt;/strong&gt;은, 세타값들을 다음과 같이 동시에 업데이트 해야한다는 것 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/theta-simultaneous-update.png&quot; alt=&quot;theta_simultaneous_update&quot; /&gt;&lt;/p&gt;

&lt;p&gt;세타값들이 위 수식에서 계속 쓰이기 때문에, 하나의 세타를 먼저 업데이트 해버리면 다음 세타의 업데이트본을 구할 때 이미 업데이트된 세타값을 사용하여 다른 알고리즘이 되어버립니다. 잘못된 순서는 &lt;strong&gt;1-&amp;gt;3-&amp;gt;2-&amp;gt;4&lt;/strong&gt; 입니다.&lt;/p&gt;

&lt;p&gt;위 식들에서 살펴볼 중요한 것들이 2가지 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;alpha값이 의미하는 것
    &lt;ul&gt;
      &lt;li&gt;alpha값이 너무 작으면, 세타가 줄어드는 속도가 느려집니다.&lt;/li&gt;
      &lt;li&gt;반대로, 너무 크면 overshooting되는 경향이 있고, local minimum으로의 수렴에 실패하게 됩니다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;따라서, 적당한 alpha값을 설정하는 것이 중요합니다.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;local minimum으로 수렴했을 경우의 세타 업데이트
    &lt;ul&gt;
      &lt;li&gt;기울기가 0이기 때문에, 미분항은 0이고, alpha * 0 또한 0입니다.&lt;/li&gt;
      &lt;li&gt;따라서 세타값 - 0은 세타값이므로, 기존의 세타값이 유지됩니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/theta-update-rule.png&quot; alt=&quot;theta_update_rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다시 이 수식으로 돌아와봅시다. 이 수식 자체를 받아들여보려는 노력을 해봅시다. 기존의 세타에서 J의 기울기 * alpha를 &lt;strong&gt;뺄셈&lt;/strong&gt;을 하는 이유를 설명하겠습니다. 직관과 이해의 편의를 위해 세타_0 = 0인 다음과 같은 이차식을 참고해주세요.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/cost-function-graph.png&quot; alt=&quot;cost_function_graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그래프의 첫번째 시작점에서 그 위의 수식을 적용해봅시다. 미분한 값, 즉 기울기가 &lt;strong&gt;양수&lt;/strong&gt;가 되므로 세타는 점점 &lt;strong&gt;가운데&lt;/strong&gt;로 내려갑니다. 마찬가지로 두번째 시작점에서 적용해봅시다. 이때는 기울기가 음수이므로, 역시 세타가 점점 &lt;strong&gt;가운데&lt;/strong&gt;로 내려가게됩니다. 따라서 결국에는 최솟값을 가지는 세타를 구하게 되는 셈입니다.&lt;/p&gt;

&lt;p&gt;그렇다면 linear regression에서 cost function J는 항상 convex할까요?
답은 &lt;strong&gt;Yes&lt;/strong&gt;입니다. 수학적으로 linear regression의 J함수는 볼록함수이기에 가운데의 최솟값으로 내려가는 것 입니다.
수학적으로는 볼록함수는 이계도함수가 양수인것을 뜻하는데요, 우리가 살펴본 cost function인 MSE(mean squared error)의 식을 두 번 미분한 것은 항상 양수이기 때문입니다. 자세한 것은 &lt;a href=&quot;https://www.quora.com/Why-is-the-cost-function-in-linear-regression-a-convex-function-How-do-we-prove-it-mathematically&quot;&gt;여기&lt;/a&gt;를 참고해보시면 좋을 것 같습니다!&lt;/p&gt;

&lt;p&gt;다음 포스트에서는 원래 Linear Algebra Review를 다룰 계획이었지만, 모두가 선형대수를 공부하였다는 가정하에 2주차로 넘어가 &lt;strong&gt;Linear Regression with Multiple Variables&lt;/strong&gt;에 대해 다루겠습니다.&lt;/p&gt;

&lt;p&gt;오탈자 / 오류 / 궁금사항 댓글로 남겨주시면 적극 반영하여 더욱 발전된 모습을 보여드리겠습니다. 궁금하신 것이 있으시면 언제든지 댓글을 남겨주시기 바랍니다. 감사합니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">ML Coursera 1-1 Introduction</title>
      <link href="https://hy38.github.io/MLcoursera-1-1" rel="alternate" type="text/html" title="ML Coursera 1-1 Introduction" />
      <published>2019-05-27T19:00:00+09:00</published>
      <updated>2019-05-27T19:00:00+09:00</updated>
      <id>https://hy38.github.io/MLcoursera-1-1</id>
      <content type="html" xml:base="https://hy38.github.io/MLcoursera-1-1">&lt;blockquote&gt;
  &lt;p&gt;Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;h2 id=&quot;what-is-machine-learning&quot;&gt;What is Machine Learning?&lt;/h2&gt;
&lt;p&gt;머신러닝은 컴퓨터로 하여금 경험들을 토대로 explicit하게 프로그래밍되지 않아도 &lt;strong&gt;학습&lt;/strong&gt;을 할 수 있게 하는 것 입니다.
이 때 학습 알고리즘에는 두가지 종류로 나뉘게 되는데, 첫번째가 &lt;strong&gt;지도학습(Supervised learning)&lt;/strong&gt; 이고, 두번째가 &lt;strong&gt;비지도학습 (Unsupervised learning)&lt;/strong&gt; 입니다. 그렇다면 지도학습부터 천천히 알아봅시다.&lt;/p&gt;

&lt;h2 id=&quot;supervised-learning&quot;&gt;Supervised Learning&lt;/h2&gt;

&lt;p&gt;지도학습을 간략하게 표현해보면, “주어진 데이터들로부터 예상값을 계산하는 것” 입니다. 너무 함축적이기 때문에 예시를 들어보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;회귀regression&quot;&gt;회귀(Regression)&lt;/h3&gt;
&lt;p&gt;친구가 집을 파려고 하는데 이 집의 크기가 750제곱피트라고 합시다. 그리고 우리는 특정 제곱피트당 집가격에 해당하는 데이터들을 가지고 있습니다. 이 사진처럼 말입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/house-price-prediction.png&quot; alt=&quot;house price prediction&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 때 750제곱피트의 친구집을 얼마의 가격에 팔아야 할 지 결정하는 것이 지도학습입니다.&lt;/p&gt;

&lt;p&gt;이 문제의 경우 어떻게 친구집의 가격을 예측할 수 있을까요? 아마 첫번째 방법은 데이터를 관통하는 &lt;strong&gt;일직선(straight line)&lt;/strong&gt; 을 긋어 750에 해당하는 y값을 찾는 방법일 것입니다. 이 경우에는 대략 $150000정도에 팔 수 있을것 같습니다. 두번째 방법은 일직선 대신에 &lt;strong&gt;2차 다항식(second order polynomial)&lt;/strong&gt; 을 적용해보는 것 입니다. 아마도 이번에는 $200000정도에 팔 수 있을것 같습니다.&lt;/p&gt;

&lt;p&gt;이 때 주목해할 것이 &lt;strong&gt;right answer&lt;/strong&gt;가 있는 &lt;strong&gt;데이터들(data set)&lt;/strong&gt; 을 알고리즘에 적용하여 문제를 해결하였다는 것입니다. 우리는 집크기에 대한 집값을 알고있기 때문에, 이 &lt;strong&gt;training data&lt;/strong&gt;들을 학습시켜 원하는 예측값을 만들어내었습니다. 학습 알고리즘은 &lt;strong&gt;training data&lt;/strong&gt;가 늘어날 수록 더 정확한 예측값을 만들어내야할 것입니다.&lt;/p&gt;

&lt;p&gt;이러한 유형의 문제들을 &lt;strong&gt;회귀(Regression)&lt;/strong&gt; 문제 라고도 합니다.
여기서 데이터에 가장 근사하게 직선을 긋는 회귀를 &lt;strong&gt;선형 회귀(Linear Regression)&lt;/strong&gt; 이라고 합니다. 이는 &lt;a href=&quot;/ml/MLcoursera-1-2/&quot;&gt;다음 포스트&lt;/a&gt;에서 알아보도록 할 것입니다.&lt;/p&gt;

&lt;h3 id=&quot;분류classification&quot;&gt;분류(Classification)&lt;/h3&gt;
&lt;p&gt;또다른 예시를 통해 지도학습을 알아보겠습니다. 미리 말씀드리자면, 이번 예시는 이전의 회귀와 다른 &lt;strong&gt;분류(Classification)&lt;/strong&gt; 문제 라고 합니다. 우리는 유방암의 크기에 따른 양성/악성 종양 여부를 표현한 데이터가 있습니다. 
&lt;img src=&quot;/assets/images/ml/coursera/week1/is-malignant-1.png&quot; alt=&quot;IsMalignant1&quot; /&gt;
이 때 종양의 크기가 주어졌을 때 이 종양이 양성인지 악성인지를 분류할 것입니다.
양성인지 악성인지는 철저하게 0(양성)과 1(악성)로 구별되며, 0과 1 중간에는 어떠한 데이터도 있어서는 안됩니다.&lt;/p&gt;

&lt;p&gt;이 때의 분류문제는 양성, 악성 2개의 클래스들로 이루어져있습니다. 하지만 얼마든지 많은 분류클래스들이 존재할 수 있습니다. 예시 클래스로는 양성, 1기, 2기, 3기, 4기 종양이 있으며, 종양 크기에 따라 이 &lt;strong&gt;5가지&lt;/strong&gt; 결과값 중 &lt;strong&gt;한가지&lt;/strong&gt;를 유추해낼 수 있을것입니다.&lt;/p&gt;

&lt;p&gt;이번에는 다른 데이터입니다. 바로 종양 크기 뿐만 아니라 환자의 나이에 따른 양성 / 악성 판별 데이터인데요, 이처럼 분류문제는 많은 &lt;strong&gt;속성(attribute)&lt;/strong&gt; 들을 가질 수 있습니다. 더 많은 속성들에는 나이, 환자 스트레스지수, 비만도 등이 있을 수 있겠죠?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ml/coursera/week1/is-malignant-2.png&quot; alt=&quot;IsMalignant1&quot; /&gt;
위 사진의 데이터들을 토대로 양성과 악성을 어떻게 구분할 수 있을까요? 저라면 단순하게 대각으로 나누는 선을 그어 분류할 것 같습니다. 이 단순한 방법뿐만 아니라 더욱 복잡한 함수를 이용하여 분류를 진행할 수도 있겠죠?&lt;/p&gt;

&lt;p&gt;추가로, 무한대의 &lt;strong&gt;속성(feature)&lt;/strong&gt; 들을 가진 데이터의 경우에는 추후에 배울 &lt;strong&gt;support vector machine&lt;/strong&gt;이라는 수학적인 방법으로 해결할 수 있습니다.&lt;/p&gt;

&lt;p&gt;여기서 attribute과 feature의 차이가 궁금하실 것입니다. 이는 &lt;a href=&quot;https://stackoverflow.com/questions/19803707/difference-between-dimension-attribute-and-feature-in-machine-learning&quot;&gt;여기&lt;/a&gt;를 참고하여 주세요.&lt;/p&gt;

&lt;p&gt;여기까지가 지도학습에 대한 소개였습니다. 이후부터는 비지도학습에 대한 소개를 진행하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;unsupervised-learning&quot;&gt;Unsupervised Learning&lt;/h2&gt;
&lt;p&gt;지도학습과 다르게 비지도학습은 unlabeled data를 다루게 됩니다. 우리는 데이터가 어떻게 구성되어있는지를 밝혀내게 되는데, 그 방법중 하나가 이 중구난방인 데이터들을 그룹으로 묶어 군집화를 하는 것입니다. 이는 &lt;strong&gt;clustering algorithm&lt;/strong&gt; 이라고 불립니다.&lt;/p&gt;

&lt;p&gt;Clustering algorithm은 비슷한 뉴스끼리 군집을 이루는 것부터 시작하여 유전학을 비롯하여 곧 알아보게 될 Cocktail party algorithm에도 이용됩니다.&lt;/p&gt;

&lt;p&gt;&lt;del&gt;지극히 사담이지만, 작년에 뉴스 기사를 군집화하는 아르바이트를 한 적이 있습니다. 덕분에 좋은 분들을 만나 인연을 맺게 되었는데요, 그 당시에는 웃프게도 군집화를 수동적으로만 진행하였지, 이것이 어떻게 활용될지를 생각하지 않았던 기억이 있습니다. 그때 조금만 더 일찍 능동적으로 생각해보았으면 어땠을까 하는 아쉬움이 남네요.&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;지도학습과의 가장 큰 차이점은 &lt;strong&gt;right answer&lt;/strong&gt;을 주지 않는다는데에 있습니다. 지도학습은 주어진 &lt;strong&gt;answer&lt;/strong&gt;를 이용하여 input feature에 해당하는 output을 예측할 수 있는 반면에, 비지도학습은 주어진 &lt;strong&gt;answer 없이&lt;/strong&gt; 데이터가 어떻게 struct되어있는지를 밝혀낸다는 의미있는 차이점입니다.&lt;/p&gt;

&lt;h3 id=&quot;칵테일-파티-알고리즘cocktail-party-algorithm&quot;&gt;칵테일 파티 알고리즘(Cocktail party algorithm)&lt;/h3&gt;
&lt;p&gt;이 알고리즘은 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EC%B9%B5%ED%85%8C%EC%9D%BC_%ED%8C%8C%ED%8B%B0_%ED%9A%A8%EA%B3%BC&quot;&gt;Cocktail party effect&lt;/a&gt;에서 비롯되었으며, 배경에 시끄러운, 겹치는 소리들이 많음에도 불구하고 원하는 소리만을 분리해내는 알고리즘입니다. 이는 비지도학습에 해당하며, (음성)데이터를 군집화하였음을 보여주는 대표적인 알고리즘입니다.&lt;/p&gt;

&lt;p&gt;이것으로 머신러닝에 대한 소개를 마칩니다.
저 또한 공부하는 학생이기 때문에 오탈자 및 내용상 오류가 존재할 수 있습니다.
오탈자 및 오류를 발견시 댓글을 남겨주시면 적극 반영하여 더욱 발전된 모습을 보여드리기 위해 노력하겠습니다.
궁금하신 것이 있으시면 언제든지 댓글을 남겨주시기 바랍니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sanghyun Park</name>
        
        
      </author>

      

      
        <category term="machine learning" />
      
        <category term="Coursera" />
      

      
        <summary type="html">Coursera Andrew Ng 교수님의 ML 강의를 정리한 포스트입니다.</summary>
      

      
      
    </entry>
  
</feed>
